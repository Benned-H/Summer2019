{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Chapter 1: Introduction",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Benned-H/Summer2019/blob/master/Speech%20and%20Language%20Processing/Chapter_1_Introduction.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MynlS1BD_h_F",
        "colab_type": "text"
      },
      "source": [
        "# Introduction (p. 1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hiKBN01Z_jbz",
        "colab_type": "text"
      },
      "source": [
        "As of 2007, this field went by the names of *computer speech and language processing* or *human language technology* or *natural language processing* or *computational linguistics*. Whatever you call it, we want computers to process human language in useful ways. Some of these ways include:\n",
        "* Conversational agents/dialogue systems - Can converse with humans via natural language.\n",
        "* Machine translation - Automatic translation between languages.\n",
        "* Question answering - As simple as definitions or factoids to as complex as inference or summarization.\n",
        "* Spell or grammar-checking too."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JJIznDU5AyVW",
        "colab_type": "text"
      },
      "source": [
        "## 1.1 Knowledge in Speech and Language Processing (p. 2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XHC0-yjYA65f",
        "colab_type": "text"
      },
      "source": [
        "A few domains of linguistics are necessary to create HAL, for example:\n",
        "* Phonetics - How words are pronounced in terms of sequences of sounds.\n",
        "* Phonology - How these sounds are realized acoustically.\n",
        "* Morphology - The way words break down into component parts.\n",
        "* Syntax - The knowledge needed to order and group words together.\n",
        "* Lexical Semantics - The meaning of words.\n",
        "* Compositional semantics - What constitutes 'Western Europe' or 'end of the 18th century'?\n",
        "* Conversation knowledge - Is a given utterance a request for action, statement, or a question?\n",
        "* Pragmatics - Knowledge about dialogue and the appropriate lexicon for a given context.\n",
        "* Discourse knowledge - Includes coreference resolution and context understanding."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7yg8vHQHKY2a",
        "colab_type": "text"
      },
      "source": [
        "Concretely, these areas can focus into:\n",
        "* Phonetics and Phonology - Knowledge about linguistic sounds\n",
        "* Morphology - Knowledge about the meaningful components of words\n",
        "* Syntax - Knowledge of the structural relationships of words\n",
        "* Semantics - Knowledge of meaning\n",
        "* Pragmatics - Knowledge of the relationship between intentions and meaning\n",
        "* Discourse - Knowledge about linguistic units larger than a sentence"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GM9q2-GXLHXw",
        "colab_type": "text"
      },
      "source": [
        "## 1.2 Ambiguity (p. 4)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ghJBkD4fLJTC",
        "colab_type": "text"
      },
      "source": [
        "Surprise surprise, we often have ambiguity and in fact most tasks can be viewed as resolving ambiguity at one of these levels. An input is **ambiguous** if there are multiple alternative linguistic structures that can be built for it. By breaking the various ambiguities into different processes, we can get a grasp on the chaos of possibilities. Some of these processes include:\n",
        "* Lexical disambiguation - Part-of-speech tagging, word sense disambiguation\n",
        "* Syntactic disambiguation - Probabilistic parsing\n",
        "* Speech act interpretation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GwlAG4CCM0rk",
        "colab_type": "text"
      },
      "source": [
        "## 1.3 Models and Algorithms (p. 5)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RbP53F3dM3ZO",
        "colab_type": "text"
      },
      "source": [
        "Certain models prove quite useful for these tasks, including **state machines**, **rule systems**, **logic**, **probabilistic models**, and **vector-space models**. Algorithms built with these such as **state space search** and **dynamic programming** turn out to be quite useful."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g7nPh0G1Naip",
        "colab_type": "text"
      },
      "source": [
        "Most simply, **state machines** are a type of formal model with states, transitions between states, and an input representation. Variations include **DFAs**, **NFAs**, and **finite-state transducers**. **Rule systems** are a related concept that define the grammars the state machines can parse: **regular grammars**, **regular relations**, **CFGs**, and **feature-augmented grammars** are a few. A third model uses **first order logic** (AKA **predicate calculus**) and related formalisms to model semantics and pragmatics."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oUjEUCYiOWS9",
        "colab_type": "text"
      },
      "source": [
        "In all of these models, a probabilistic nature becomes crucial for capturing linguistic knowledge. One example, the **Markov model**, can be created by adding probabilities to a state machine. The crucial reframing this gives us is to change the problem definition into: \"Out of these $N$ ambiguous choices, choose the most probable one.\" Processing languages through these models involved a search through a space of states representing hypotheses about an input. Heuristic variants such as **best-first** or **A*** rely on dynamic programming to remain computable."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "REt26fArPqMW",
        "colab_type": "text"
      },
      "source": [
        "Machine learning models also help out, including:\n",
        "* Classifiers - Decision trees, support vector machines, Gaussian Mixture Models, or logistic regression\n",
        "* Sequence models - Hidden Markov model, Maximum Entropy Markov Models, or Conditional Random Fields\n",
        "\n",
        "Methodological tools used in machine learning also help, such as **cross-validation**."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r3McA_6jQQwh",
        "colab_type": "text"
      },
      "source": [
        "## 1.4 Language, Thought, and Understanding (p. 6)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WR5_nvkiQgIg",
        "colab_type": "text"
      },
      "source": [
        "*--Continue on p. 6--*"
      ]
    }
  ]
}